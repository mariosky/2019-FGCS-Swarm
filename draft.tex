\documentclass[review]{elsarticle}

\usepackage{lineno,hyperref}

\modulolinenumbers[5]

\journal{Future Generation Computer Systems}
\begin{document}

\begin{frontmatter}

\title{An Event-based Architecture for Multi-population Optimization Algorithms}

\author[itt]{Mario Garc\'ia Valdez}\corref{mycorrespondingauthor}
\cortext[mycorrespondingauthor]{Corresponding author}
\ead{mario@tectijuana.edu.mx}

\author[granada]{Juan J. Merelo Guerv\'os}
\ead{jmerelo@geneura.ugr.es}

\address[itt]{Department of Graduate Studies, Instituto Tecnol\'ogico de Tijuana, Tijuana BC, Mexico}
\address[granada]{Universidad de Granada, Granada, Spain}

\begin{abstract} 
Multi-population based methods have been used extensively in
recent years to improve the performance of nature-inspired optimization
algorithms, these methods are parallel and asynchronous by nature and researchers
leverage this to scale algorithms % scale algorithms or implementations? - JJ
with distributed, multi-threaded,
parallel and cloud-based implementations. However, the design  of cloud-native,  distributed, multi-population algorithms is not a trivial task. Designers need to adapt the algorithms, while keeping its nature, to
leverage the scalability, elasticity, fault-tolerance,
reproducibility, and cost-effectiveness of reactive cloud-based systems. % reactive is mentioned here for the first time. Possibly you should just refer to "cloud-native" and then specify that it implies asynchrony, reactivity, and so on - JJ
In this
work, we present the design and implementation of a reactive container-based
application for the execution of multi-population algorithms. Researchers can
use the application to execute multiple experiments, both locally or in a cloud
environment and deploy experiments by specifying the infrastructure as part of
an experiment definition so that results are easily reproducible. We
evaluated the performance of the platform and the benefits of a multi-population
approach by using an ensemble of Genetic Algorithms (GAs) and Particle Swarm
Optimization (PSO) in a benchmark for the optimization of continuous functions.
Experiments show that the framework allows the ensemble to outperform
single-algorithm versions. The framework we provide also has fewer parameters to
tune since subpopulation parameters are selected randomly. The architecture and
the implemented platform is an excellent alternative for locally or a
cloud-based deployment.
\end{abstract}

\begin{keyword}
Multi-population \sep Nature-inspired algorithm \sep Parallel Genetic Algorithms \sep Cloud-Computing
\sep Event-driven architecture 
\end{keyword}

\end{frontmatter}

\linenumbers

\section{Introduction}

In the last decades, nature-inspired optimization algorithms have been succesfully
applied to solve complex real-world problems \cite{yang2014nature}. Algorithms
inspired by natural processes include evolutionary algorithms (EAs)
\cite{back1996evolutionary} and swarm intelligence (SI) \cite{kennedy2006swarm},
among others. These population-based algorithms share the common characteristic
of using an initial set of random candidate solutions that are later used to
generate a new set of candidates, using a nature-inspired heuristic. Popular EAs
are Genetic Algorithms (GAs), Genetic Programming (GP), grey wolf optimization
(GWO) and Differential Evolution (DE), while examples of (SI) are particle swarm
optimization (PSO) and ant colony algorithms (ACO).

Population-based algorithms are intrinsically parallel, and can be implemented in an asynchronous. % They needn't be intrinsically asynchronous, I think. Most are implemented synchronouslu - JJ
The fitness of each individual can be evaluated independently of
others, and similarly, each population could evolve in isolation. Since 
earlier works, researchers have been proposing some form of parallelization
\cite{muhlenbein1988evolution} to increase the scalability of these algorithms.
The island model was one of the first techniques proposed for parallelization,
which lead to an increased performance \cite{gorges1990explicit,grosso1985computer}. 
The concept was to divide a large population into communicated subpopulations. 
Since then, other population-based algorithms have adopted the concept, 
and researchers have found additional benefits
besides the execution speed; these include avoiding a premature convergence and
maintaining the diversity of the global population. Researchers use the term
multi-population based methods when generally referring to techniques using
subpopulations as part of their optimization strategy. % Some comment about asynchrony would be in order - JJ

When designing efficient multi-population algorithms, researchers need to
consider additional issues. These include the number and size of subpopulations,
the interaction between them, the search area of subpopulations, and the search
strategy and parametrization of each subpopulation. We must take into account
these high-level issues when designing a parallel architecture. 

The parallel execution of multi-population algorithms has been the focus of many
works,  going from earlier hardware-based implementations using transputers,
multi-threaded, and multi-core systems. % many citations here - JJ
Recently the trend has been on
exploiting a higher number of processing units by using GPUs, or distributed
systems; techniques used to achieve this include client-server, web-based, map-reduce,  grid, and cloud computing. % many references here too - JJ
Cloud
computing has become the standard way of running enterprise applications, not
only because of the convenience of the pay-as-you-go model or the non-existent
cost of administration, but also because it offers a way of describing the
infrastructure as part of the code, so that it is much easier to reproduce
results and this has been a boon for scientific computing.  However,  cloud computing
has also been evolving, going from simply putting in the cloud old-style monolithic applications, that is,
applications built on a single stack of services that communicate by layers, to
microservice and serverless architectures that favor the parallel and
asynchronous communication of heterogeneous resources; in the process, a new process for designing {\em cloud native applications} has been created, with brand new methodologies and techniques. In these architectures,
services or even functions are seen as single processing points,  departing
from the monolithic and even distributed paradigms, become a loosely coupled collection of 
{\em stateless functions}, that react to events and only come into existence while they 
are doing some processing. % many references more here - JJ

% Again, you have to justify the need for a reactive architecture and define it before this paragraph - JJ
Based on a reactive architecture \cite{guervos2018introducing} , each
subpopulation is represented as an event message that is pushed asynchronously
into a message queue. Incoming messages trigger stateless functions that receive
the subpopulation and proceed to run an algorithm, using the parameters and
population included in the message. After the specified number of iterations,
each stateless function returns the evolved subpopulation by again pushing a
message to another queue, used for receiving the resulting subpopulations.
Subpopulations are received from the queue by a controller that is responsible
for mixing the individuals from different subpopulations and producing new
subpopulations. These new subpopulations are pushed again by the controller into
the message queue, creating a loop. The cycle stops when the controller receives
a subpopulation containing a candidate solution that satisfies a particular
condition, or a maximum number of messages were received.

% There is a big gap here where you go from generic considerations
% about cloud computing to the presentation of this method. In the
% middle, there should be motivation for it, what are you trying to
% address precisely, and how you intend to address it. "Approaching
% multi-population algorithms in cloud computing" is not nearly
% enough. There are several points here, and every one of them needs
% to be addressed and justified
% * Using containers as opposed to a serverless architecture or a
% virtual-machine based one.
% * Combining several metaheuristics instead of using a single one.
% * Reducing the amount of parameters.
% There needs to be a motivation for every one, relate them to the
% objectives of the paper (which need to be clarified) and eventually
% prove the contribution of every one of them to the final result - JJ
Taking these factors into account, in this work, we present Swarm, % maybe a less generic name? - JJ
a
multi-container Docker application that reactively processes isolated and
heterogeneous subpopulations. The platform uses the Docker Compose tool for
defining and running experiments as multi-container applications. % Docker compose is not really for production, more for development environments, you have to justify this. Also, it does not handle scaling so need to justify it too - JJ
Docker
Container images host the stateless functions responsible for running algorithms
on subpopulations. Researchers then define the configuration of services used by
a multi-population algorithm using a YAML file. Any researcher can deploy and
start all the services from this configuration file with a single command. Once
the services are up, multiple instances of an experiment can be sent to a queue
for their execution. The platform includes containerized services that are
compatible with other container orchestration technologies like Kubernetes and
Docker Swarm. The services included are a Redis Server used for the Message
Queue implementation and logging and an Experiment Controller implemented in
Python. Developers of sub-population processing functions have the freedom to
implement new population-based algorithms or operators in the language they
choose inside a container, as they only need to subscribe to a channel of the
Message Queue and have the ability to read the population and parameters as JSON  
file.

This paper extends our earlier publication on the topic
\cite{guervos2018introducing}, and we highlight the main contributions as
follows:

\begin{itemize}
    \item First, we present the design and implementation of a reactive 
    container-based application for the asynchronous execution of multi-population 
    algorithms. The source code and example container definitions are
    publicly available. % Not really a contribution. It's the mean to
                        % achieve the contribution - JJ
    \item Second, we propose a method for the deployment and execution of 
    multiple experiments by specifying the infrastructure as part of an 
    experiment definition in both local or cloud environments,
    facilitating the reproduction of experimental results. % Not clear
                                % what the contribution is. If this
                                % has been used for the first time in
                                % an EA environment, it should be
                                % stated that way. If not, it's also a
                                % mean to achieve the contribution - JJ
    \item Third, the application is compatible with the COCO benchmark 
    framework, allowing researchers to compare the performance of their 
    algorithms with other works. % Not really a contribution, but an
                                % implementation detail. Convenient,
                                % but does not advance the state of
                                % the art - JJ
    \item Lastly, we present an empirical study to validate the 
    applicability of our application,  measuring the execution time, 
    speedup, and a comparison between homogeneous and an ensemble of 
    multi-populations, using Genetic Algorithms (GAs) and Particle 
    Swarm Optimization (PSO) in a benchmark for the optimization of 
    continuous functions. % "Validate the applicability" falls short
                          % of being also a contribution. It must
                          % advance the state of the art, in which way
                          % does it advance? Speed (needs to be
                          % proved) Convenience (needs to be proved
                          % too) Scalability? (needs to be proved
                          % also). - JJ
\end{itemize}

% The rest of the paper is organized as follows...

% A state of the art should be included here too - JJ

\section{Multi-population design}

Multi-population based methods divide the original population into
smaller subpopulations or islands, with every subpopulation carrying out the
algorithm independently, with synchronous or asynchronous communication with the
rest of the islands. % exemplify how this is done in different
                     % metaheuristics, especially those we will be
                     % using here - JJ
This relative isolation helps in maintaining an overall
diversity since each subpopulation will search in a particular area, at least
between communications. The recombination mentioned above (mixing) or migration
between subpopulations is needed to avoid a premature convergence of candidate
solutions since smaller populations are known to perform better for a given
problem than bigger populations. % Smaller populations converge
                                % prematurely or perform better? - JJ
However, it gives them the added advantage of
parallel operation. Additionally, and in some cases, multi-population algorithms
scale better than expected due to the interaction between the algorithm and the
parallelism of the operation \cite{ALBA20027}. % Need to clarify this
                                % and if it extends to Swarm
                                % algorithms too

However, in most cases, algorithms applied to each subpopulation are
homogeneous, or at any rate, the same variant of the algorithm. As long as this
parallel operation is not synchronous, other population-based algorithms, or, as
a matter of fact, any algorithm, could be easily integrated. That is why several
works based on multi-population are heterogeneous, integrating various
optimization algorithms, and often performing better than single-population or
homogeneous optimization algorithms \cite{wu2016differential,nseef2016adaptive}.

Heterogeneous algorithms add another degree of freedom to the problem of finding
the correct parameter settings for an algorithm; because some parameters affect
the accuracy of the solution and the convergence speed of the algorithms as they
tip the balance between exploration and exploitation of the search space. On the
other hand, current studies show that by having a high number of subpopulations
interacting in parallel, the effect of the individual parameters of each
subpopulation is compensated by those selected in other subpopulations. In this
work, we will use random settings within a specific range as results have shown
this is a valid solution to this problem. 

Some parameters, specially the population size, are
kept fixed in order to control more easily the execution of the algorithm. For
instance, by having the size of subpopulations fixed, it is easier to control
the number of evaluations and the communication costs, when the algorithm is in
operation.

Combining multiple algorithms, with different parameters, interacting with each
other at the same time, can benefit from the strengths of each. For instance, a
genetic algorithm could find a promising global solution that is not optimal
while another algorithm, more suitable for a local search, finds the global
optimum. This approach has been followed extensively in recent years, with
success. Moreover, there is a need for frameworks, architecture, and
implementation models that can allow researchers the development of new
parallel, asynchronous, heterogeneous, and parameter-free algorithms in a scalable way.  


\bibliographystyle{elsarticle-num}
\bibliography{multipopulation,serverless}

\end{document}