\documentclass[review]{elsarticle}

\usepackage{lineno,hyperref}
\usepackage{rotating}
\usepackage{algpseudocode,algorithm}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}

\lstset{
basicstyle=\small\ttfamily,
}

\graphicspath{ {./images/} }

\modulolinenumbers[5]

\journal{Future Generation Computer Systems}
\begin{document}
\lstset{language=Python} 
\begin{frontmatter}

  \title{EvoSwarm: An Event-based Architecture for Multi-population Optimization Algorithms}
  % maybe introduce "reproducible" here, somewhere, as well as "cloud native"

\author[itt]{Mario Garc\'ia Valdez}\corref{mycorrespondingauthor}
\cortext[mycorrespondingauthor]{Corresponding author}
\ead{mario@tectijuana.edu.mx}

\author[granada]{Juan J. Merelo Guerv\'os}
\ead{jmerelo@geneura.ugr.es}

\address[itt]{Department of Graduate Studies, Instituto Tecnol\'ogico de Tijuana, Tijuana BC, Mexico}
\address[granada]{Department of Computer Architecture and Technology, Universidad de Granada, Granada, Spain}

\begin{abstract} 
Splitting a population into multiple instances is a technique that has
been used extensively in recent years in order to help improve the
performance of nature-inspired optimization algorithms. Work on those
populations can be done in parallel, and they can interact asynchronously,
a fact that can be leveraged to create scalable implementations based
on, among other methods, distributed, multi-threaded, parallel, and
cloud-native computing.  However, the design of these cloud-native,
distributed, multi-population algorithms is not a trivial task. Coming
from monolithic (single-instance) solutions, adaptations at several
levels, from the algorithmic to the functional, must be made to
leverage the scalability, elasticity, (limited) fault-tolerance,
reproducibility, and cost-effectiveness of cloud systems while, at the
same time, conserving the intended functionality. Instead of an
evolutive approach, in this paper we propose to create from scratch a
cloud-native optimization framework that is able to include multiple
algorithms and use few parameters to work. This solution goes beyond
current state of the art via a framework that is able to support
different algorithms at the same time, work asynchronously, and also
be easily deployable to any cloud platform. We evaluate the
performance and scalability of this solution, together with the effect
other design parameters had on it; in particular, the number and the
size of populations with respect to problem size. The architecture and
the implemented platform is an excellent alternative for running
locally or in the cloud, thus proving that cloud-native bioinspired
algorithms perform better in their ``natural'' environment than other
kinds of algorithms, % Did we compare it to other kind of algorithms?
                     % If we didn't, this should go - JJ 
                     % Compared against GA and PSO and others from BBOB - Mario
                     % on the algorithm, not speedup 
and setting a new baseline for scaling and
performance in the cloud.
\end{abstract}

\begin{keyword}
Multi-population \sep Nature-inspired algorithm \sep Parallel Genetic Algorithms \sep Cloud-Computing
\sep Event-driven architecture 
\end{keyword}

\end{frontmatter}

\linenumbers

\section{Introduction}

In the last decades, nature-inspired optimization algorithms have been successfully
applied to solve many complex real-world problems
\cite{yang2014nature}; these algorithms can be broadly grouped into evolutionary algorithms (EAs)
\cite{back1996evolutionary} and swarm intelligence (SI)
\cite{kennedy2006swarm}, as well as other categories; popular EAs
are Genetic Algorithms (GAs) \cite{holland1992adaptation,eiben2003genetic}, 
Genetic Programming (GP) \cite{back1996evolutionary}, Grey Wolf Optimization
(GWO) \cite{mirjalili2014grey} and Differential Evolution (DE) \cite{karabouga2004simple},
while examples of (SI) \cite{kennedy2006swarm} are particle swarm
optimization (PSO) \cite{clerc2010particle} and ant colony algorithms (ACO) \cite{dorigo1999ant}.

Besides being all population-based, they also share the common characteristic
of creating an initial set of random candidate solutions that are later used to
generate a new set of candidates, using a nature-inspired heuristic.
Population-based algorithms are intrinsically parallel, and can be implemented to run asynchronously.
The fitness of each individual can be (in general) evaluated independently of 
others, and similarly, each population could evolve in isolation. Researchers use the term
multi-population based methods when generally referring to techniques using
many populations as part of their optimization strategy. 
Since 
earlier works, researchers have been proposing some form of parallelization
\cite{muhlenbein1988evolution} to increase the scalability of these
algorithms that adds to this simple parallel execution some form of
interaction between the independently running populations.
The island model was one of the first techniques proposed for parallelization,
which led to an early proof of speedup   \cite{gorges1990explicit,grosso1985computer}. 
The concept was to divide a large population into communicated subpopulations. 
Since then, other population-based algorithms have adopted the concept, 
and researchers have found additional benefits
besides the execution speed; these include avoiding a premature convergence and
maintaining the diversity of the global population \cite{li2015multi}. 

% Probably it's not the time for this, but maybe it would be interesting to 
% mention that asynchronous implementations in most cases need a change in 
% the underlying algorithm, while synchronous might not need it - JJ 
% TO DO - Mario 
Moreover, parallel implementations can run in two different ways: synchronous and
asynchronous. When operations run in parallel but every node must maintain synchrony with
the other operations,  all operations need to finish to continue to the next
step. For instance, in a  master/worker model, the master needs to wait for all
workers to finish their operations before moving to the next iteration.  In
contrast, in an asynchronous execution,  operations are not synchronized with
each other, so there's no time lost waiting for other populations to
arrive to the synchronization point; results arriving from other workers are 
incorporated as soon as they are received. Following the previous example, now the master operation can
continue to the next iteration, even if a worker has not finished its work.  In
the literature, we can find many asynchronous algorithms
\cite{coleman89,baugh2003asynchronous}, reporting benefits in execution time,
and scalability. In the particular case of asynchronous and cloud-native
multi-population algorithms, recent works propose an asynchronous communication
through a central repository \cite{sofea:cec2012, JSON} or message queues
\cite{salza2019speed, guervos2018introducing}, in this work we follow this
practice.

The trend concerning the parallel execution multi-population algorithms goes from
earlier hardware-based implementations using transputers
\cite{gorges1990explicit} through 
multi-core systems \cite{Serrano2008,lai2019adaptive} to multi-threaded \cite{merelo2019scaling} ones.
And recently the focus has been on exploiting a higher number of processing
units by using GPUs \cite{tan2015survey,li2007efficient}, or distributed
systems, including web-based \cite{JSON} systems,
map-reduce \cite{fazenda2012} implementations,  grids \cite{munawar2010design,Gonzalez09},
voluntary computing systems \cite{MilkyWay}, % Maybe add one of our own voluntary computing references? - JJ
and, more importantly, cloud computing
\cite{GValdez2015,salza2019speed,valenzuela2015implementing,FlexGP}. Cloud computing has become the standard way of running
enterprise applications, not only because of the convenience of the
pay-as-you-go model or the non-existent sunk cost of physical facilities, but also because
it offers a way of describing the infrastructure as part of the code, so that it
is much easier to reproduce results and this has been a boon for scientific
computing.  However,  cloud computing has also been evolving, going from simply
putting on virtual machines elsewhere than on premises old-style monolithic applications, that is, applications
built on a single stack of services that communicate by layers, to microservices
\cite{microservices} and serverless architectures \cite{varghese2018next,Varghese2018849} that favor the parallel and asynchronous communication of
heterogeneous resources; in the process, a new methodology for designing {\em cloud
native applications} has been created, with brand new methods and
techniques \cite{Baldini2016287}. In these architectures, services or even
functions are seen as independent processing nodes, departing from the monolithic
and even distributed paradigms, and becoming a loosely coupled collection of {\em
stateless functions} \cite{malawski2017serverless}, that react to events and
only come into existence while they are doing some processing.
Systems developed with the patterns outlined above have the
properties of a reactive system \cite{boner2014reactive} and they are commonly
more flexible, fault-tolerant, and scalable. % Some properies and reference - Mario  
% Again, you have to justify the need for a reactive architecture and define it before this paragraph - JJ

Researchers 
and algorithm designers willing to  adapt to the cloud their
multi-population solutions face the additional challenges:
\begin{itemize}
    \item They need to change their current solutions to a reactive architecture in which processes
    communicate with each other by exchanging messages asynchronously and react
    to a continuous stream of data. One of the options is to consider
    populations as messages to be modified asynchronously by functions. 

    \item To scale the system, when it is possible, there are several options, including the  use of stateless functions for
    processing. 

    \item They need to establish a workflow of local development and prototyping while having the 
    option of deployment in a cloud provider. It is desirable to use modern development methodologies and technologies. 

    \item They must log experimental results and be able to replicate the experiments. 

    \item They must consider additional parameters that can affect the monetary cost or the performance of the
    execution — for instance, the format and size of messages, the number of
    worker processes and their capabilities.  
\end{itemize}

% I have moved these sentences here, since they seem to fit the best.(OK - M)
Beyond the choice of design methodology and implementation, researchers need to
consider additional issues \cite{Ma2019} when designing efficient multi-population algorithms. These include the number and size of populations,
the interaction between them, the search area of each population, and the search
strategy and parametrization of each population. We must take into account
these high-level issues when designing a parallel architecture.

Taking these factors into account, in this work, we present EvoSwarm, 
a container-based application that reactively processes
isolated and
heterogeneous populations. The platform uses the Docker Compose tool for
defining and running experiments as multi-container applications. EvoSwarm is also released with a free licence in \url{https://github.com/mariosky/EvoSwarm}.
We preferred the use of a container-based application for this prototype because
it is more suitable for development and replication without the need for
additional components. Nevertheless, the application is compatible with other
orchestration and deployment technologies if more scalability is needed. 
With additional configuration settings, applications can be deployed 
to a Docker Swarm or a Kubernetes system.  

Docker container images host the stateless functions responsible for 
running a search strategy on populations they receive as messages. 
A single container can pull many messages on its lifetime, processing one at a time. 
% clarify "on several populations" Sequentially? At the same time? - JJ 
% done - M
These functions could also be ported
directly to a Function as a Service (FaaS) \cite{Roberts2016} implementation.
% Need to improve the next paragraph or maybe move it to another place - Mario
Researchers then define the configuration of services used by
a multi-population algorithm using a YAML file. Any researcher can deploy and
start all the services from this configuration file with a single command. Once
the services are up, multiple instances of an experiment can be sent to a queue
for their execution. The platform includes containerized services that are
compatible with other container orchestration technologies like Kubernetes and
Docker Swarm. The services included are a Redis Server used for the Message
Queue implementation and logging and an Experiment Controller implemented in
Python. Developers of population processing functions have the freedom to
implement new population-based algorithms or operators in the language they
choose inside a container, as they only need to subscribe to a channel of the
Message Queue and have the ability to read the population and parameters as JSON  
file.

This paper extends our earlier publication on the topic
\cite{guervos2018introducing}, and we highlight the main contributions as
follows:
We have proved that cloud-native applications are
able to easily accommodate multi-paradigm bioinspired algorithms
with little efforts of parametrization and
that a combination of algorithms has better speedup and performance
than any single one taken independently.

We have proved this in the following steps:
% The reviewer says that we should clarify the contributions, and the
% contribution should answer a research question. Maybe we should
% clarify these contributions to answer to that. Contribution should
% be something like "We have proved that cloud-native applications are
% able to easily accommodate multi-paradigm bioinspired algorithms
% with little efforts of parametrization and
% that a combination of algorithms has better speedup and performance
% than any single one taken independently.
% These items above could be preceded by "We have proved this in the
% following steps" - JJ
% I like it will put it just like that. 
% A reviewer also put enph   asis on the workflow and reproductivility 
% and extracting a Model? we can put something on that too.
% yep. 

% Maybe here you should make reference to the sections where you are actually doing it (after conveniently rephrasing it) - JJ
\begin{itemize}
    \item First, we present the design and implementation of a reactive 
    container-based application for the asynchronous execution of multi-population 
    algorithms. The source code and example container definitions are
    publicly available. % Not really a contribution. It's the mean to
    % achieve the contribution - JJ
    % Maybe you should check this out again ... - JJ
    \item Second, we propose a new method for the deployment and execution of 
    multiple experiments by specifying the infrastructure as part of an 
    experiment definition in both local or cloud environments,
    facilitating the reproduction of experimental results. % Not clear
                                % what the contribution is. If this
                                % has been used for the first time in
                                % an EA environment, it should be
                                % stated that way. If not, it's also a
                                % mean to achieve the contribution - JJ
    \item Third, the application is compatible with the COCO benchmark 
    framework, allowing researchers to compare the performance of their 
    algorithms with other works. % Not really a contribution, but an
                                % implementation detail. Convenient,
                                % but does not advance the state of
                                % the art - JJ
    \item Fourth, we present an empirical study to validate the 
    applicability of our application,  measuring the execution time and  
    speedup.
    
    \item Lastly, we present a comparison between homogeneous and an ensemble of 
    multi-populations, using Genetic Algorithms (GAs) and Particle 
    Swarm Optimization (PSO) in a benchmark for the optimization of 
    continuous functions. % "Validate the applicability" falls short
                          % of being also a contribution. It must
                          % advance the state of the art, in which way
                          % does it advance? Speed (needs to be
                          % proved) Convenience (needs to be proved
                          % too) Scalability? (needs to be proved
                          % also). - JJ 
\end{itemize}

The organization of the paper is as follows: First, in Section \ref{multi}, we present a
background of the fundamental issues of integrating nature-inspired optimization
and multi-population methods. Section \ref{soa} presents state of the art relevant to
our work. In Section \ref{method}, we present the proposed method and the container-based
application in Section \ref{docker} and the workflow for experiment design in Section \ref{experiment_flow}. % No reference to section 6.
Section \ref{setup} describes
the design of the empirical evaluation we designed to assess the effectiveness
of the method, scalability is analysed in Section \ref{sec:exp1}, % This is a subsection, fix it. 
the performance of heterogeneous populations in Second \label{sec:exp2} 
and a cloud deployment example in Section \ref{cloud-aws}. % No references to sections 9 and 10
Finally, we
offer the conclusions of this paper and suggestions on future work in Section \ref{conclusions}.


\section{Multi-population methods} % Is this part of the state of the
\label{multi}
                                % art? - JJ
% This the Background for the design decisions, but I think is also needed
% to better understand the state of the art.
% I don't know. Maybe it should be directly merged with the state of
% the art, if there's some essential to our paper it should go to the
% introduction - JJ

% Also, multipopulation design of what?x
Multi-population based methods divide the original population into
smaller populations or islands, with every population carrying out the
algorithm independently, with synchronous or asynchronous communication with the
rest of the islands \cite{Ma2019}.% exemplify how this is done in different
                     % metaheuristics, especially those we will be
                     % using here - JJ
This relative isolation helps in maintaining an overall
diversity since each population will search in a particular area, at least
between communications. The recombination mentioned above (mixing) or migration
between populations is needed to avoid a premature convergence of candidate
solutions since smaller populations are known to perform better for a given
problem than bigger populations \cite{li2016multi,wu2016differential}. % Smaller populations converge
                                % prematurely or perform better? - JJ
However, it gives them the added advantage of
parallel operation. Additionally, and in some cases, multi-population algorithms
scale better than expected due to the interaction between the algorithm and the
parallelism of the operation \cite{ALBA20027}. % Need to clarify this
                                % and if it extends to Swarm
                                % algorithms too
                                % Also, is your objective to achieve this superlinear speedup? - JJ

However, in most cases, algorithms applied to each population are
homogeneous, or at any rate, the same variant of the algorithm. As long as this
parallel operation is not synchronous, other population-based algorithms, or, as
a matter of fact, any algorithm, could be easily integrated. That is why several
works based on multi-population are heterogeneous, integrating various
optimization algorithms, and often performing better than single-population or
homogeneous optimization algorithms \cite{wu2016differential,nseef2016adaptive}.

Heterogeneous algorithms add another degree of freedom to the problem of finding
the correct parameter settings for an algorithm; because some parameters affect
the accuracy of the solution and the convergence speed of the algorithms as they
tip the balance between exploration and exploitation of the search space. On the
other hand, current studies show that by having a high number of populations
interacting in parallel, the effect of the individual parameters of each
population is compensated by those selected in other
populations \cite{li2016multi,tanabe2013evaluation}. % reference - JJ

%%%%% ----------------- This gets lost in this section -----------------------------
In this work, we will use random settings within a specific range as results have shown
this is a valid solution to this problem \cite{garcia2014randomized}. % This should have been
                                % mentioned in the introduction - JJ

%%%%%% -------------------- This too. Should go up, to intro, or down,
%%%%%% to method - JJ
Some parameters, specially the population size, are
kept fixed in order to control more easily the execution of the algorithm. For
instance, by having the size of populations fixed, it is easier to control
the number of evaluations and the communication costs, when the algorithm is in
operation. % And to keep them more or less synchronized, which can be
           % interesting, too... But this should go to the
           % introduction also - JJ

%%%% ---------------------- Also to the introduction
Combining multiple algorithms, with different parameters, interacting with each
other at the same time, can benefit from the strengths of each. For instance, a
genetic algorithm could find a promising global solution that is not optimal
while another algorithm, more suitable for a local search, finds the global
optimum. This approach has been followed extensively in recent years with
success \cite{li2015multi,godio2016multi,biswas2014co}. 
Moreover, there is a need for frameworks, architecture, and
implementation models that can allow researchers the development of new
parallel, asynchronous, heterogeneous, and parameter-free algorithms in a scalable way.  

\section{State of the Art} 
\label{soa}

Although at first sight containers look like simply a method that
allows easy shipping of applications, they are much more than
that. One of the first features that make them interesting is their
ephemerality: fast startup and teardown time make them usable for
machine-independent and cloud deployment of simple, ephemeral and
maybe stateless functions. On the other hand, containerization also
allows, through the use of orchestration engines like Docker Swarm or
Kubernetes, or through simple, non-self-scaling specifications using
Docker Compose, a definition of all the relationships between
different parts of the application, or services. The full realization
of Docker-based architectures has led to the creation of a series of
patterns that, together, conform cloud-native application development
\cite{kratzke2017understanding}.

However, in the field of evolutionary algorithms, this has been a slow
realization, from the origins where Salza and Ferrucci
\cite{salza2016approach,salza2016develop} proposed an architecture
that carried evolutionary algorithms to the cloud, and which were
developed further in their next paper \cite{de2017parallel}. These
papers started to introduce cloud native aspects such as the use of
messaging queues and CoreOS as an operating system designed from the
ground up for container utilization in the area of evolutionary
algorithms. The way these containers are managed, however, is rather
classical in nature from the point of view of distributed EC: a
master-worker approach, communicated using RabbitMQ (a messaging
queue), where replicated workers perform the tasks in parallel. They
called their approach AMQPGA, inspired by the protocol, AMQP, used by
RabbitMQ, the messaging system. This classical approach has been also
followed by other authors by using other EA ``classical'' topologies
in the cloud: Dziurzanski et al. \cite{dziurzanski2020scalable} adapts an island model to
a container architecture, in a system that is functionally equivalent
to classical models, but with the added advantage of being easy to
deploy and run.

Later approaches use microservices \cite{khalloof2018generic}, or were
systematized \cite{salza2019speed} achieving speed-up through the
creation of an abstraction layer over the evolutionary algorithm
services, and also automation of the whole workflow. This research
bumped into some problems, since speedup is limited, mainly due to the
non-automatic scaling of services and also the presence of a single
master which is the one that runs the evolutionary
algorithms. However, this master-worker architecture can be turned
around with other kind of evolutionary architectures, such
as pool-based systems
\cite{valenzuela2015implementing,merelo2012sofea,sofea:cec2012} where
a better match to the inherently heterogeneous nature of cloud-based
architectures. Pool-based systems are closer to serverless systems
\cite{malawski2017serverless}, and they pull from the pool and run
whole algorithms, instead of just evaluation. The pool from where they
pull is the common store of results, and can be accessed in an
asynchronous way, which suits better the nature of cloud systems.


% a lot of this has been done in the previous method... Maybe there's
% not that much to do - JJ
% Hadoop 
%     Comparison \cite{ferrucci2018using}
%     Hadoop\cite{fazenda2012} 
%     FlexGP \cite{FlexGP}, 
%     elephant56 \cite{salza2016elephant56},

% Pool
%     SofEA \cite{merelo2012sofea,sofea:cec2012} , 
%     EvoSpace \cite{garcia2015evospace},
% Volunteer
%     evospace-js \cite{garcia2017evospace}
% Queue
%     Containers \cite{valenzuela2015implementing} \cite{salza2016approach} 
%     Seamless local and Cloud \cite{leclerc2016seamless}
%     Serverless KafKEO \cite{guervos2018introducing}, 
%     Docker Orchestation \cite{dziurzanski2020scalable,zhao2019cloud}
% PSO 
% PSO AWS \cite{li2015parallel}



\section{Proposed Method} 
\label{method} 

In this section, we present the design
and a container-based implementation of the model we propose for the execution
of multi-population based algorithms. We follow the requirements outlined in
Section \ref{multi} and the general design principles of cloud-native
applications we have mentioned earlier; our intention is to steer
clear of a direct translation of ``classical'' GA architectures to the
cloud and design from the ground up a cloud-native method. As a first step, we describe the general
architecture, and then  every component in detail. 

The most elemental data structure used throughout the system is the population; and at a higher
level, we can view the system as a continuous stream of populations
flowing from one process to the other. By ``continuous stream,'' we mean that ideally,
everything must happen asynchronously without components needing to wait for
others. In this kind of system, this streaming functionality is normally
implemented by using a message queue system. For instance, if one process needs
to communicate a population to another, it must pack the population into
a message, and then send the message 
to the queuing system without waiting for a response; this
means that after the process pushes the message, it continues its execution
without waiting for a result. On the other end, the recipient subscribes to the
message queue by defining an event handler method that is going to be triggered when a
message is pushed to it. The two components at each end of the queue are
Producers that push messages to the queue and Consumers that pull them. This
pattern is an essential component of a reactive architecture and makes
it 
highly scalable; one of the reasons for this is the use of functions
that have no secondary effects or access global storage, that is,
stateless functions. These functions do not need to read, keep, or modify data outside of the method. If
Consumers are implemented using stateless functions, and thus, there is no difference
between having one or many copies of the same function pulling work from the queue all at the
same time, because no side effects, including unwanted resource
locking problems,  are going to result from this concurrency.
% This is important and we should probably mention that in the
% introduction - JJ 
Based on these general principles we define next the proposed model.


\begin{sidewaysfigure}
    \centering
    \includegraphics[width=\textwidth]{KafkEOsmall}
    \caption{The proposed general architecture, 
     showing each process in a swimlane, message-dataflow,
     message queues, and high-level tasks for each process.} 
    \label{fig:kafkEO}
\end{sidewaysfigure}

\subsection{Event Driven Model} 
\label{edm}
Based on a reactive architecture we proposed in a previous work
\cite{guervos2018introducing}, we now describe the general architecture shown in
Figure \ref{fig:kafkEO}. Again, we can explain the model using the analogy
of producers and consumers of messages. First, we can see that
there are two queues, one labeled \texttt{Input}, and the other one \texttt{Output}. In the diagram, 
push operations on a queue are represented by solid arrows connecting to the left side
of the queue box, and pull or pop operations as solid arrows leaving from the right side.
Also, the architecture has at least four processes indicated in the diagram as
swimlanes: First, the \texttt{Setup} process, responsible for the reading a configuration
file, and creating the initial populations. Second, the \texttt{Controller} process,
responsible for the migration between populations, and keeping track of the
iterations of the algorithm. The \texttt{Message Queue} process runs the \texttt{Input} and \texttt{Output}
queues. Finally, there is at least one \texttt{Stateless Function} process responsible
for running the isolated algorithms. In the example, two processes \texttt{PSO} and \texttt{GA},
are shown. 

The algorithm starts with the \texttt{Setup} process pulling a configuration message from
the \texttt{Experiments} queue, this is not shown in the diagram. The configuration message 
includes all the parameters needed to execute the algorithm, among other things,
the number of populations, the number of individuals, and the number of iterations
of the algorithm. We give more details about the configuration data structure
in Section \ref{experiment_flow}. % Missing  % added 
Once the configuration is read, we can follow the path of 
messages as follows:

\begin{enumerate}
\item In this step, the specified number of populations are created according to the 
parameters found in the configuration structure. The population at this moment is just
static data, including each individual inside. Each population includes a metadata
section where its algorithm and execution parameters are specified. For instance, 
for a GA, the mutation rate, type of crossover operator, and other values are indicated.

\item Each population is then pushed to the \texttt{Input} queue, so they can be consumed 
by Stateless functions responsible for the execution of the search.

\item One or more \texttt{Stateless functions} are constantly pulling population messages
from the \texttt{Input} queue. Taking the population data and metadata as parameters, these 
functions are responsible for the actual execution of the optimization algorithm. 
They take the current state of the population and run the algorithm for a certain 
number of iterations. 

\item Once they finish the execution, the population state
is packed again along with additional metadata about the execution of the algorithm.
The resulting populations are now pushed to the Output queue. Once finished, another 
population is pulled from the queue.

\item The \texttt{Controller} process is responsible for keeping track of the progress of 
the search. It pulls current populations from the \texttt{Output} queue, inspects the metadata 
and if an optimal solution has been found or the maximum number of iteration has been
reached it signals the stop of the execution. 

\item Otherwise, it passes the stream of messages 
to a migration process, where populations are mixed with each other. New populations 
are generated from this migration, and they are again pushed to the Input queue to continue 
in a loop. The \texttt{Controller} is also responsible of logging the metadata received with the
messages.  
\end{enumerate}

This reactive architecture has the following advantages:\begin{itemize}
\item 
An important aspect of proposal is the decoupling of the population and 
the population-based algorithm. It is common that in a classic island-based algorithm
each island is executed in a separate processing node, i.e. in a virtual machine, CPU,
or thread. In this case we can have just one processing node, or many nodes, each 
running a different search strategy, or using its own parameters. 
\item 
Also, the reactive controller gives designers more control over the multi-population algorithm.
In this process, designers can dynamically change the number of populations, population parameters,
and migration details on-the-fly.
\item 
Another advantage is that algorithm designers have many options for implementing this simple architecture. 
The same basic components can be implemented as a single multi-threaded program, or 
as a highly scalable serverless cloud application. Most modern languages include 
constructs for asynchronous programming using queues or channels, for a multi-threaded
execution.
\end{itemize}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{population_message}
    \caption{Population State and dataflow between processing nodes of a message-based algorithm.}
    \label{fig:population_message}
\end{figure}

On the other hand, there are several caveats as well:
It is more costly to move entire populations as messages than only passing certain individuals 
from a process to another. Designers must consider this cost when working with large
individuals, and if possible send populations using several messages, use compression or 
adjust the size of populations. Pool-based algorithms also suffer from this drawback, but 
web based implementations have been working with continuous optimization problems of 1000 dimensions.
But, in other cases this is not a viable approach. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{classicisland}
    \caption{ Population State and dataflow between processing nodes of a classic Island-based multi-population algorithm. }
    \label{fig:classicisland}
\end{figure}

\subsection{Comparison with other cloud-based works} 
\label{comparison}

Next, we compare the message-driven architecture we presented against four other
proposals for multi-population algorithms found in the literature. We center the
comparison on the coupling and communication between the main components:
populations, processing nodes, and algorithms.  In Figure \ref{fig:population_message} we show the
main components of a message-driven architecture. We can see that the algorithm
and populations are separated, and the \texttt{Population queue} keeps the state
of populations. While algorithms only need the populations as parameters
for their execution.

% We need to add references to the respective papers - Mario

In contrast, in the classic island model shown in Figure
\ref{fig:classicisland}, algorithms are  population methods, and the same processing
node keeps both the algorithm process and the state of the population.  Other
processing nodes follow the same configuration and form of execution, and they
only pass specific individuals between them.  In this model, adding additional
processing nodes, on-runtime, can be more difficult, because they need to have
an addressing mechanism or simply be aware of these new nodes. This is
solved in part in Peer to Peer (P2P) evolutionary algorithms
\cite{juanlu:europar}, but coupling still exists, meaning that every
node must run the whole evolutionary algorithm and hold full copies of
its subpopulation. 
% JJ, help I don't know if this is clearly understood, a mean like a
% DNS - Mario
% Added something - JJ

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{pool_island}
    \caption{Population state and flow of data between processing nodes of a Pool-based multi-population algorithm.}
    \label{fig:pool_island}
\end{figure}

A typical design pattern used to alleviate the above drawbacks is the use of a
central repository or pool of individuals that is available to all processing
nodes.  In Figure \ref{fig:pool_island} we show the main components of a pool-based
multi-population algorithm. Although algorithms and population state remains
coupled, now, processing nodes do not communicate directly with each other.
Instead, they interchange individuals with the pool. Communication between nodes
is not affected if the system adds or removes nodes because they do not know
about each other.  Since the state of the global population is stored in
external processing nodes, the system needs additional communication and
processing for keeping track of each population.

We show another pool-based approach in Figure  \ref{fig:population_pool}. In
this design, the global population is stored in a central repository, while
isolated algorithms take random samples of the global population and use this
temporal population as parameters. An advantage of this design is that the
sampling provides a type of migration between isolated populations. A problem
found is that when a processing node returns a population to the pool, the
state of the population is lost. But having the algorithm decoupled opens the
possibility of implementing the system using serverless functions.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{population_pool}
    \caption{Population State and dataflow between processing nodes of the EvoSpace algorithm.}
    \label{fig:population_pool}
\end{figure}


% Maybe these three sections should be merged; they are all experimental set up and the two next ones start with "experimental"
% (and he next one too) - JJ
% done - Mario
% But also change title? - JJ
% Experimental design of a container-based application or something like that - JJ
\section{Container-based application} 
\label{docker}

We have mentioned several advantages of a cloud-native application for running
multi-population based algorithms, but there are in our experience several
practical issues of this approach. % several issues that make it practical or useful instead? - JJ
In general, cloud platforms have free-tiers
for their services, and many offer academic discounts to students. But once we
pass to the pay-as-you-go tier, computing resources need to be
managed, and, where possible, its cost minimized.  First,
in many cases,  a credit-card is needed to guarantee the payment of the
resources consumed and someone responsible for assigning quotas and, more
importantly, special keys for using the cloud's API.  If these keys are
compromised or shared by their holders,  additional costs or administrative
procedures are in order. For those cases when a prototype platform is needed,
for instance, students developing a new algorithm variant or experimenting with
a published work, a container-based platform can be more practical. Container
technology enables researchers the local deployment of all the infrastructure
needed to run the experiments. Later, if needed, the same system could be
deployed to the cloud.

% The main advantage of container deployments over virtual machine
% instances is that they add much less overhead to communication between
% them, and they are much more economical to deploy. Scaling and
% monitoring can be done much more easily through cloud orchestration
% systems such as Kubernetes; these are the reasons why we chose it for
% this work.
% I don't see this line of argument. You can do exactly the same with
% virtual machines instead of containers. Also, you can test a virtual
% infrastructure locally and then only when it's needed deploy it to
% the cloud. If you want to give good reasons for using containers
% instead of virtual machines, there are quite a lot non-economic ones
% - JJ
% OK, I will add an issue - Mario
% Did you finally? - JJrehe
% I did not, will add and assign it - M
There are many advantages of container-based architectures over one
based on virtual machines. The main ones are architectural: it makes
the design of an application gravitate towards a set of decoupled
tasks, that use reactive, event based programming, to interact with
the rest of the application; containers hold micro-services that are
much easier to test, integrate and deploy. It also simplifies
the interaction APIs. Of course, that makes them more economical in a
pay-per-use cloud provider, but that is not the main reason why we
have chosen them in this paper; reproducibility of experiments and a
clear and idempotent description of the architecture through docker
compose % Be consistent with docker compose. Either {\tt docker-compose} or {\sf docker-compose}, but not docker compose, for instance. - JJ
are the main reasons. 

In this section, we propose a design of a reactive container-based application
for executing multi-population based optimization experiments.  For the design,
we followed the design patterns highlighted in the previous section, and again
we can go back to Figure \ref{fig:kafkEO} and use it as a guide for explaining
the main components and their interactions. The containers used in this design will be explained next. 

% But first, we give a brief description of the technology we used. 

% Add if needed
%\subsection{Containers} 
%\label{containers}
% TO DO

%\subsection{Docker Compose} 
%\label{compose}
% TO DO
 

% Do we need a description of every container? Wouldn't a general 
% description  of the containers used be enough? - JJ 
% Ok, I think only workers and the controller need to be described in detail - Mario 
\subsection{Message Queue Container} 
\label{message_container}

In this work, we implemented all message
queues in the Redis memory store. Early cloud architectures
\cite{de2017parallel} used queues for communication, although in that
case RabbitMQ was the chosen tool. Redis is faster, and also can act
as a data store from where we can control the state of the application.
Each queue is a Redis List object, and we use
the \texttt{LPOP} (left pop), and \texttt{RPOP} (right pop) commands for a queue like behavior.
In those cases where we needed a blocking behavior, i.e., when a process needs
to wait until a message is available, we used the blocking versions \texttt{BLPOP} and
\texttt{BRPOP}. Redis in-memory operation are very fast, and all of the above 
operations have a time complexity of $\mathcal{O}(1)$. We use the official 
\texttt{redis:alpine} container image from DockerHub.  

\subsection{Controller Container} 
\label{controller}

The controller is an essential component of the architecture (see Figure \ref{fig:kafkEO})
because it is responsible for maintaining the evolutionary loop. It takes newly
evolved populations from the \texttt{Output Queue}, mixes them,   and produces new
messages from the result. At the same time, it must keep track of two conditions
for ending the loop: the number of messages it has received reaches a maximum
value, or the error of the best solution goes below a specific threshold.  Finally, it
must filter out remnant messages from other experiments. Messages from other
experiments can remain in the queues because of the asynchronous nature of the
system.  We chose to implement the controller in Python but using an API
specialized in asynchronous event-driven programming over data streams.  
The open-source library is called Reactive Extensions (ReactiveX) for Python 
\url{https://github.com/ReactiveX/RxPY} an it is based on the Observer 
pattern \cite{gamma1995design} and functional programming.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{marble_controller}
    \caption{Marble diagram for the Reactive Python implementation of the Controller}
    \label{fig:marble_controller}
\end{figure}

In ReactiveX, an \texttt{observer} object subscribes to an \texttt{Observable} instance. 
Observables emit a sequence of items, and all the subscribed observers react to each emission. The
ReactiveX library includes several reactive operators that we can use to
transform and combine sequences of items. These operators provide reactive
extensions that allow us to compose asynchronous sequences together in a
declarative manner. In Figure \ref{fig:marble_controller}, we use a marble diagram to
represent the composition of \texttt{Observables} and reactive extensions operators. We
represent the timeline of an \texttt{Observable} as a horizontal arrow, which indicates
that time flows from left to right. In the diagram, items are represented as
marbles. The position of each marble indicates the point in time when they were
emitted by the \texttt{Observable}. Reactive operators are represented as text boxes,
showing the transformation to be applied. Normally, a transformation results in
another \texttt{Observable}, again emitting new results.  For asynchronous programming, 
this approach is more elegant than nested callbacks, that are more difficult 
to code and debug. 

Now we proceed to explain the reactive implementation of the controller.
In Figure \ref{fig:marble_controller}, we  have the following composition of Observables:

\begin{enumerate}
\item The controller continually pulls new messages from the \texttt{Output} 
message queue. These messages are instantly emitted by the  \texttt{consumed\_messages}
\texttt{Observable}. In this particular period, we can see that the stream receives 
two populations from another experiment, and are shown as two red marbles.  
The filter operator removes all messages that belong to a different experiment; 
in this case, we are only interested in blue marbles. 

\item The \texttt{max\_iterations} parameter indicates the number of populations that
are going to be accepted. When this number of messages is reached, we must
end the loop. In this example, \texttt{max\_iterations = 6},  the take operator 
assures that only 6 messages are received. After the \texttt{Observable} emits 
the sixth message, it triggers the completed event.

\item Many observers can be subscribed to the \texttt{valid\_messages} \texttt{Observable} because it
emits all the valid items. At the moment, there are to additional methods
subscribed that we are not showing, one for logging and the other for monitoring
the search.

\item The   \texttt{buffer\_with\_count(3)} operator, waits until it receives 
three valid messages to emit a single message that contains a list with
the previous three. The \texttt{population\_mixer}  method requires that list to mix them. 
In our previous work, we needed a local buffer for storing a certain 
number of populations to mix them with others. This design has the advantage
of not needing extra memory, and it integrates better with the reactive paradigm.
A possible disadvantage can be that it only mixes contiguous populations,
but this can be mitigated with a larger buffer.

\item The \texttt{population\_mixer} receives a list of three populations,
let us say [A, B, C], and calls the migration method shown in
Algorithm \ref{alg:migration}  for [A, B], [B, C] and [A, C]. 
The migration algorithm sorts both populations and generates
a new population containing the best half from each.
This migration method is similar to those used successfully in previous 
works on pool-based algorithms \ref{fig:pool_island}.  
Finally, the method pushes the new populations to the 
\texttt{messages Observable}. From there, a
\texttt{publish(population)} observer is responsible for pushing
the newly generated populations back to the \texttt{Input} message queue.
\end{enumerate}

\begin{algorithm}
    \caption{Migration}
    \label{alg:migration}
    \begin{algorithmic}[1]
        \Procedure{cxBestFromEach}{$pop_1,pop_2$}
            \State $pop_1.sort()$
            \State $pop_2.sort()$
            \State $size\gets min(len(pop_1), len(pop_2))$
            \State $cxpoint\gets (size-1)/2$
            \State $pop_1[cxpoint:]\gets pop_2[:cxpoint+2]$
            \State \textbf{return} $pop_1$
        \EndProcedure 
    \end{algorithmic}
\end{algorithm}



In the next section, we follow the algorithm flow and describe the 
implementation details of the \texttt{worker} containers. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{worker_new}
    \caption{Serverless function implementation details. Showing the worker algorithm in each container}
    \label{fig:worker}
\end{figure}


% Maybe you should say here how everything wors: launch with
% Docker-compose, whatever. That's the issue that one of the reviewers
% say - JJ 

% This issue is also commanted in the experimental section
% I will explain it and then we can see where it goes. - M  

\subsection{Worker Containers} 
\label{workers}

Worker containers include a Python script called \texttt{main.py} running an
infinite loop, continually trying to pull a new population to work on it. Once
\texttt{main.py} receives a message containing configuration data, it creates a
worker object responsible for initializing and running the specified stateless
function (i.e., GA or PSO) with the population and configuration in the message.
Once the function returns the evolved population, the
the main script pushes the results to the \texttt{Output} queue, and continues
the execution to the infinite loop. This process is shown in Figure
\ref{fig:worker}.

\section{Experimental Workflow in EvoSwarm} % We could upgrade this to a section and explain in detail 
% taking care of #5 - M
\label{experiment_flow}

% You can't start with this. Explain what this section is about, and link it with the previous one. Maybe it's better to create a big section with "Experimental setup", and make this a subsection, with subsections becoming subsubsections - JJ
Figure \ref{fig:experiment_flow} shows the general workflow to run experiments
in Evo\-Swarm, and the three roles users can play. The first step is to develop the
search strategy algorithms that are going to be used by the multi-population
algorithm; algorithm developers do this. Then administrators are responsible for
the installation and configuration of the application. Once the application is
running, users can start one or several experiments, monitor the execution, and
analyze the results. Depending on the type of experiment executed, users could
have additional needs, in this case there are additional scripts for
processing the results of experiments to be used with the COCO framework. In the
next sections, we give more details about these roles and their workflows.  

\begin{sidewaysfigure}
    \centering
    \includegraphics[width=\textwidth]{experiment_flow}
    \caption{EvoSwarm Workflow}
    \label{fig:experiment_flow}
\end{sidewaysfigure}

\subsection{EvoSwarm from the developer point of view} 

Developers can add new algorithm as stateless functions in
several ways and with two levels of integration. In the first level of
integration, the algorithm execution is not dependent on an initial
configuration created in the setup, and it only needs to take messages from the
input queue and return the modified population to the output queue. On the
second level, the algorithm receives a configuration from the initial setup,
specifying the initial algorithm parameters. We show an example of the configuration
file received by workers in Listing \ref{code:config}  in which we abbreviated
the population key (the ellipsis is used instead). The message includes the current state
of the population, together with data about the problem, algorithm,
and its parameters. 

\begin{lstlisting}[language=Python, caption = Configuration message example, label=code:config]
{"problem":{
  "name":"BBOB","instance": 1,"error":1e-8,"function":4,
  "dim":3,"search_space":[-5,5],
  "problem_id":"1515-4-1-3",
  "max_iterations": 20,
  "population":[
          [ -3.323452321611405, 
             2.593007989886873, 
             3.001112341167673],
             ...
          [ -2.22e343232411405, 
             2.593007989886873, 
             2.0011025031167673] 
          ],
  "population_size": 100,
  "algorithm": "GA",  
  "params":{
      "GA":{"crossover": { "type": "cxTwoPoint", 
            "CXPB_RND": [0.2, 0.6], "CXPB": 0.26},
             "mutation": { "MUTPB_RND": [0.1, 0.3], 
             "indpb": 0.05, "sigma": 0.5, 
             "type":"mutGaussian","mu":0,"MUTPB":0.12},
             "selection": { 
               "type": "tools.selTournament", 
               "tournsize": 2 },
               "iterations": 50},
       "PSO": {"Vmax":5,"wMax":0.9,"wMin":0.2,
               "c1":2,"c2":2,"iterations":50 } 
    },
  "experiment":{"type":"benchmark","experiment_id": 1515}
  }
}
\end{lstlisting}

In the case of the first level of integration, developers
can implement a new stateless Docker container following
the description in the previous section (\ref{workers}). The worker
container executes a daemon that continuously pulls messages from the input queue
on the Redis host specified as an environment variable {\texttt REDIS\_HOST}. If the new
population-based algorithm is written in Python, developers can base the new
implementation on the provided worker container image, adding a new algorithm
function and worker and modifying the \texttt{main.py} file. 
The worker must include a constructor with the configuration dictionary 
(see Listing \ref{code:config}) as the only parameter, and call a the new function 
with the required parameters, unpacking them from the configuration dictionary if necessary.
All the code of the EvoSwarm Application is published with the open source MIT license.

If developers use an existing library for population-based algorithms, they need
to change the standard model of execution, that creates first a random
population because, in this case, the algorithm needs to start with the
population provided as a parameter. Depending on the evolutionary (or other) algorithm library used,
it may be required to extract the population from the
JSON message and replace the population object created by the default library implementation. For
example, the DEAP library we used for the GA algorithm, creates the type of the
population at runtime (i.e., bit, float), so we have to replace the population
once DEAP created it. In the case of EvoloPy, the PSO method directly uses a
list of floats for storing the swarm, so we just added a parameter to receive
the population as a list of floats. Both libraries store information about each
iteration, so we just read it and put it in the format required.
Again, the state of the population must be encoded as a JSON message to be
returned as a result, with additional data as
depicted in Listing \ref{code:result}. The output message contains the id of the
worker container together with records giving information about each iteration
of the algorithm, including the best solution found. The controller uses this
information to track the execution of the algorithm and keep a log in the Redis
container for posterior analyses.

\begin{lstlisting}[language=Python, caption=Fragment of output message, label=code:result ]
{
"time_stamp": 1588455316.698875,
"evals": [
  {
    "gen_num": 0, "best_fitness": -259.96925945939404,
    "best_solution": [ -4.9446848321611405, 
                        2.593007989886873, 
                        2.0011025031167673],
    "num_of_evals": 17
  },
  {
    "gen_num": 49, "best_fitness": -419.47555780783347,
    "best_solution": [ -0.9165294450108963, 
                        2.291966676472422, 
                        1.8527006568795485],
    "num_of_evals": 28
  }
],
"worker_id": "4f5eb12e-8278-40de-b0f3-4ac18171566d",
"message_counter": 1,
"message_id": "cbcd2e82-e232-4818-8aec-2cd072c7cfe9",
"best_score": -419.47555780783347
}
\end{lstlisting}

For the secondary level of integration, developers need to add code to the setup

container
in the current configuration message (see Listing \ref{code:config})
workers executing a GA, initialize the mutation and crossover 
probabilities randomly from a specific range of values. Users specify
this range on the experiment configuration. 
Migration between populations is independent of the type of algorithm, as the
controller treats messages as the same type of objects. But developers could
also change the controller to specify new rules of operation, for instance, to
change the type of migration depending on the algorithm. 
For example, in the case of swarm-based algorithms,  migration between  
populations (swarms) can follow a topology, indicating valid connections 
between them (i.e., ring or hypercube). The controller
can apply these rules selectively only to swarm-based algorithms. 
In general, these configuration options will be algorithm and library specific. 


On either level of integration and after making the changes outlined before,
algorithm developers can upload the container 
definition or images directly to a public repository like DockerHub. 

Another option is to upload the container image definition (Dockerfile) to GitHub and
define a trigger to re-upload the image to the registry after an update. Having
images publicly available can contribute to the reproducibility of experiments.
Moreover, having more algorithms available can benefit researchers trying to
compare against other algorithms or increase the diversity of their algorithms
by adding more search methods. Finally, in some cloud services, having hosted
images is a requirement, as it is the case of Amazon ECS.

Moreover, public repositories have the functionality for documenting, sharing,
and tracking different versions of both images and image definitions by using
tags. This infrastructure supports the objective of the paper, which is to
contribute to the reproducibility of experiments and platform independence.

% You said "subsections will talk about roles", this is not a role. Change the title to that of a role. Would that be administrator? - JJ

\subsection{EvoSwarm Configuration}
\label{sec:evoswarm:config}
The administrator role is responsible for
editing the Docker Compose configuration files that reference the images created
by developers. To deploy the application, he or she needs to edit the {\tt
docker-compose.yml} file to specify the type and number of containers required
for the experiments. The {\tt docker-compose} application is responsible for
starting all the containers, and downloading new versions if it is necessary,
by executing the command {\tt docker-compose up}  inside the EvoSwarm directory

% Also, it's a bit short. Maybe merge it into the next? - JJ

% Again, not a role - JJ
\subsection{Experiment Execution}
\label{sec:exeperimentalDefinition}

After starting the application, users can push several Experiment Definition 
files at a time and start monitoring the current execution in the terminal.
After an experiment is finished, the user must execute another script
that takes as argument the experiment id to generate a collection of files containing all the
data generated by the experiment, again in a JSON format. An example of an 
experiment definition is shown in Listing \ref{code:exp}. We give more details about the 
data contained in the file in the next section.

\begin{lstlisting}[language=Python, caption=Experiment definition example, label=code:exp]
{
"DIM_CONFIGURATION" : 
 {
 "2":{"GEN":40,"POP_SIZE": 50,"MAX_ITER":10,"MESSAGES":10},
 "3":{"GEN":25,"POP_SIZE": 60,"MAX_ITER":20,"MESSAGES":10},
 "5":{"GEN":28,"POP_SIZE": 60,"MAX_ITER":30,"MESSAGES":10},
 "10":{"GEN":50,"POP_SIZE": 70,"MAX_ITER":30,"MESSAGES":10},
 "20":{"GEN":66,"POP_SIZE":100,"MAX_ITER":30,"MESSAGES":10},
 "40":{"GEN":80,"POP_SIZE":125,"MAX_ITER":40,"MESSAGES":10}
 },
"GA_WORKER_RATIO" : 0.5,
"FUNCTIONS": [4],
"DIMENSIONS" : [2, 3, 5, 10, 20, 40],
"CXPB_RND": [0.2, 0.6],
"MUTPB_RND": [0.1, 0.3]
}
\end{lstlisting}

% This is totally unexpected. Whose role is this? You didn't even introduce it. Also, extremely short - JJ
\subsection{Using the COCO Framework}

Researchers can use these files to analyze and plot experiment data.  Python
scripts are included in the repository to plot the running times for the
experiments, and all other plots used in this paper;  there is also a script to
generate the files needed by the COCO framework \cite{hansen2016coco}, which can generate standard
comparisons against other methods.

% You should clarify that, before, you were explaining how to set up an experiment. In this section, you are explaining the experiments that you are doing in this paper. But you should relate both sections to the general objectives of the paper. In the prior section, you want to prove that EvoSwarm can be used by the public to create reproductive research (and maybe you should add a small conclusion sub or sub-sub section), in the next you explain the experiment we are doing for this paper. It would be interesting to make references from the next section to the previous one, indicating how the general setup of EvoSwarm helps _us_ to create this experiment - JJ

\section{General Experimental Setup} 
\label{setup}

We aimed to learn if the proposed solution can efficiently
improve the scalability and performance of population-based optimization
algorithms. % If you want to prove it *improves*, you need to provide a baseline. 
            %What will be your baseline? You need to specify anyway 
            %in which way it really improves - JJ
            % The baseline is a single population GA or PSO? - M
% For instance. But I was actually looking for another word that does not imply a comparison - JJ
Hence, in the following sections, we verify the following:

% JJ these are the three experiments, please check them. The last two addressing
% issues from a reviewer - M 

\begin{itemize}
\item Can we improve the execution time of the algorithm by adding populations
 and serverless functions to the system and, in particular, what is its effect on the scalability of the system? % Improve with respect to what? Single population? Please explain carefully the issues and how scaling is related to the number of populations. - JJ
 
\item Does having a multi-population enabled platform, with heterogeneous populations and
the support for mixing search strategies,  increase the performance of the
search by needing fewer function evaluations than a homogeneous setting? % But in this case the answer is no, right? - JJ
                                                                         % Is yes, but is in the second experiment - M
\item Can EvoSwarm as a cloud-native, container-based application,  be deployed
locally or in the cloud by just specifying the configuration of container images
and resources to an orchestration service? % This does not fit in here... It's related to reproducibility, and as such belongs in the previous section. The subsections that answer this should also go to the previous section - JJ
\end{itemize}

% Also, point forward to the section (or subsections) that will be devoted to proving each point. BTW, they should probably be subsections.

To validate these questions, we used benchmark functions from the Continuous
Noiseless BBOB testbed, which is part of the Comparing Continuous Optimizers
(COCO) framework \cite{hansen2016coco}. The testbed includes 24 real-parameter,
single-objective benchmark functions, and the capability to provide additional
instances of each function. Each instance of a function has a different optimal
value. The standard benchmark of the testbed utilizes 15 instances per function
over 2, 3, 5, 10, 20, and 40 dimensions. The maximum number of Function
Evaluations (FEs) changes according to the dimension (D), and it is determined
by the expression $10^5 \cdot D$. As an example, if we have $D = 2$, the
maximum number of FEs is $200,000$.
% How do you manage to stop exactly at that number of evaluations in a distributed system? - JJ
% In the controller we check the number of messages received, we assume that each message 
% needs a X amount of #FEs we stop at the maximum number of messages parameter.
% If the solution is found we stop sending messages and ignore messages from that
% experiment ID - M

The COCO framework offers several tools to compare the performance of
algorithms, generating data sets, tables, and reports for an experiment. There
is a repository\footnote{\url{https://coco.gforge.inria.fr/doku.php?id=algorithms-bbob}} 
of more than 200 results for the noiseless BBOB testbed, collected from 
BBOB workshops and special sessions between the years 2009 and 2019. The
EvoSwarm application includes an adapted version of the noiseless BBOB testbed,
compatible with the scripts of the framework, to compare with other algorithms
in the repository.

To test the heterogeneous multi-population capabilities,  we compare the
performance between a homogeneous and an ensemble of multi-populations, using
Genetic Algorithms (GAs) and Particle Swarm Optimization (PSO). For the GA
implementation, we used the DEAP library \cite{fortin2012deap} and for the PSO,
the EvoloPy library \cite{faris2016evolopy}. Both Python libraries are
open-source. In EvoSwarm these two algorithms are implemented as stateless
functions.

\begin{table}[h!tbp]
  \small
  \caption{DEAP GA EvoWorker Parameters }
  \label{tab:GAparams} 
  \centering
  \small
  \begin{tabular}{|l|c|}
    \hline
    Selection & Tournament size=12                            \\ \hline
    Mutation & Gaussian $\mu=0.0$, $\sigma=0.5$, indbp=0.05   \\ \hline
    Mutation Probability & [0.1,0.3]                          \\ \hline
    Crossover & Two Point                                     \\ \hline
    Crossover Probability  & [0.2,0.6]                          \\ \hline
  \end{tabular}
\end{table}
%
\begin{table}[h!tbp]
  \small
  \caption{ EvoloPy PSO Parameters }
  \label{tab:PSOparams} 
  \centering
  \small
  \begin{tabular}{|l|c|}
    \hline
    $V_{max}$ & 6 \\ \hline
    $W_{max}$ & $0.9$ \\ \hline
    $W_{min}$ & $0.2$ \\ \hline
    $C_1$ & 2 \\ \hline
    $C_2$ & 2 \\ \hline
  \end{tabular}
\end{table}

Next, we show the parameters for each algorithm, with Table \ref{tab:GAparams} for
the GA and Table \ref{tab:PSOparams} for PSO. We obtained these parameters
following the same method as in a previous work \cite{garcia2017benchmarking}.
To obtain the parameters, we tested first on the Rastrigin separable function
with five dimensions. After about fifteen experiments, the most challenging
targets were achieved for this particular function. We tested again with
functions one to three, and after obtaining favorable results, the PSO and GA
algorithm parameters were set. In the GA, we randomly set the mutation and
crossover probabilities to have more heterogeneous workers; % highlight this and add citation - JJ 
% done below - M
in these parameters, the range of values is specified. We did not change these parameters during the 
experiments, and only the population size and number of generations were
provided as parameters. This strategy has been applied successfully for increasing 
the performance of multi-population algorithms without requiring the setting 
of initial parameters \cite{garcia2014randomized}.

The experiments can be easily reproduced by using the configuration
files the EvoSwarm application uses to run the noiseless BBOB testbed
experiments as seen in Section~\ref{sec:exeperimentalDefinition}. % Specify this a bit more (with commands such as
             % docker-compose up and so on and use an itemize
             % environment to highlight it and answer to the reviewer
             % - JJ
             % Done, a few lines down - M
As a first step, we must deploy the docker application using a
{\tt docker-compose.yml} file, as described in Section~\ref{sec:evoswarm:config}. 
Then a JSON file containing the configuration parameters of the
experiment has to be provided.  Table \ref{tab:params} shows an example of these
parameters. The {\em GA-PSO Ratio} parameter indicates the proportion of
populations that will use the GA algorithm.  In the example, with a value of
$0.50$ there will be about the same proportion of GA and PSO populations. If we
specify a value of $0$, this will give us an algorithm with only PSO
populations, and finally, a value of  $1$ means that all populations will run
the GA algorithm. % Opening up the door to ask for testing with
                  % different proportion. You have to justify this
                  % value - JJ  
                  % We mention earlier that we replicated the params of another paper - M 

\begin{table}[h!tbp]
  \small
  \caption{ Experiment configuration example 
  }
  \label{tab:params}
  \centering
  \small
  \begin{tabular}{|l|l|l|l|l|}
    \hline
    \multicolumn{3}{|l|}{Parameter}                    & Type             & Example         \\ \hline
    \multicolumn{3}{|l|}{Worker Containers (Docker Compose)}        & \texttt{int}     & \texttt{8} \\ \hline
    \multicolumn{3}{|l|}{GA-PSO Ratio}                 & \texttt{decimal} & \texttt{0.5}    \\  \hline
    \multicolumn{3}{|l|}{Benchmark Functions}          & \texttt{list}    & \texttt{[1, 2, 3, 4, 5]} \\ \hline
    \multicolumn{3}{|l|}{Instances}                    & \texttt{integer}    & \texttt{15} \\ \hline
    \multicolumn{3}{|l|}{Dimensions}                   & \texttt{list}    & \texttt{[10, 20, 40]}        \\ \hline
    \multicolumn{3}{|l|}{Crossover Probability Range}  & \texttt{list}    & \texttt{[0.2, 0.6]}      \\ \hline
    \multicolumn{3}{|l|}{Mutation  Probability Range}  & \texttt{list}    & \texttt{[0.1, 0.3]}      \\ \hline
    \multicolumn{5}{|c|}{Dimensions}                                                      \\ \hline  
    Dimension               & Generations & Population Size & Populations  &     Iterations    \\ \hline
            10              & 50      & 140                 &      5                 & 30                \\ \hline
            20              & 66      & 200                 &      5                 & 30               \\ \hline
            40              & 80      & 250                 &      5                 & 40                \\ \hline
  \end{tabular}
\end{table}


Next, we specify a list indicating which of the 24 benchmark
functions will be tested. In the example, the experiment will use the first five
functions.  The {\em Instances} parameter indicates how many instances of each
function will be tested. {\em Instances}  has a default value of 15. We used this
value because it is the standard for the BBOB benchmark \cite{hansen2016coco}.
In the {\em Dimensions} parameter, we define a list of the dimensions that will
be tested, and we must select additional parameters for each dimension.
According to the maximum number of function evaluations (FEs) we mentioned
earlier, we define for each dimension: the number of populations that will be
generated in the setup, and for each population,  the number of generations, and
population size. Finally, the {\em Iterations} parameter indicates how many
complete loops will be performed. All these parameters give us the maximum
number of FEs that will be performed. For instance, for $D = 2$, the maximum
number of FEs is $200,000$, which is the same as $40*50*10*10$.

For local experiments we have deployed the EvoSwarm application in a
Desktop PC with an AMD Ryzen 9 3900x 12-core processor with 24 threads with a 3.8 GHz base clock, 
and 16 GB RAM. We used Docker version 19.03.3, build a872fc2f86, and docker-compose version 1.21.0, 
in Ubuntu Linux 18.04; coce is run using Python 3.7.5. Container images and the docker-compose file are available at
\url{https://hub.docker.com/u/mariosky}, and \url{https://github.com/mariosky/EvoSwarm} respectively. 
The BOBB experiments were performed with COCO \cite{hansen2016coco} version bbob.v15.03 in Python, 
the plots were produced with version 2.3.2. % Are we using BBOB plots? - JJ

% Maybe subsection? Also say the question you're answering - JJ
\section{Measuring Scalability}
\label{sec:exp1}
% Experiment 1
As we mentioned before % say where - JJ
, reactive systems can scale by adding additional copies
of serverless functions. In our case, we can start additional worker containers
to have the same effect. Other authors, like Salza et al. \cite{salza2019speed},
have used a
similar architecture, which implies that worker nodes need to have at least a certain level
of complexity, in terms of execution time,  to effectively scale on multiple
nodes, tending to linear scalability. In that paper, Salza et al. tested scalability
by simulating the work of nodes by using a sleep function and messages of different sizes.
In a population-based algorithm like EvoSwarm, several parameters can increase or 
decrease the workload of workers:

\begin{itemize}
    \item The number of populations: if there are more workers than populations, workers
    must wait for work to arrive. If there are too many populations, they could be
    standing in the queue for more time.
    \item The size of populations and the number of generations:
    These parameters naturally increase the execution time.
    \item The complexity of the algorithm: For instance, in our case,
    the PSO implementation has a lower execution time than the GA.
\end{itemize}


\begin{table}[h!tbp]
  \small
  \caption{Parameters used in the experiments with ten populations
  }
  \label{tab:params:10}
  \vspace{0.25cm}
  \centering
  \small
  \begin{tabular}{|l|c|c|c|c|c|c|}
    \hline
    Dimension        & 2  & 3  & 5  & 10 & 20  & 40  \\ \hline
    Generations      & 40 & 25 & 28 & 50 & 66  & 80  \\ \hline
    Population Size  & 50 & 60 & 60 & 70 & 100 & 125 \\ \hline
    Populations      & 10 & 10 & 10 & 10 & 10  & 10  \\ \hline
    Iterations       & 10 & 20 & 30 & 30 & 30  & 40  \\ \hline  
  \end{tabular}
\end{table}
%
\begin{table}[h!tbp]
  \small
  \caption{Parameters used in the experiments with five populations
  }
  \label{tab:params:5}
  \vspace{0.25cm}
  \centering
  \small
  \begin{tabular}{|l|c|c|c|c|c|c|}
    \hline
    Dimension        & 2  & 3  & 5  & 10 & 20  & 40  \\ \hline
    Generations      & 40 & 25 & 28 & 50 & 66  & 80  \\ \hline
    Population Size  & 100 & 120 & 120 & 140 & 200 & 250 \\ \hline
    Populations      & 5 & 5 & 5 & 5 & 5  & 5  \\ \hline
    Iterations       & 10 & 20 & 30 & 30 & 30  & 40  \\ \hline  
  \end{tabular}
\end{table}

\subsection{Setup}

To evaluate the effect of these parameters on the scalability of the system, we
propose  an experiment in which we selected $f_4$ (Skew Rastrigin-Bueche separable) from the
BBOB testbed. This function has been used because it is computationally demanding,
and in higher dimensions has been difficult for PSO \cite{el2009black} and GAs
\cite{nicolau2009application} to solve with the required FEs. As we
are only comparing in terms of execution time, the results from a single function
can be better understood, since there are fewer factors involved.
Following the procedure described in the previous section, we executed 
two sets of experiments with five and ten initial populations,
repeating each experiment 30 times using  1, 2, 4, and 8 workers.  We kept the same 
maximum number of FEs, changing the relevant parameters for this. 
See Tables \ref{tab:params:10} and \ref{tab:params:5} 
for the complete list. 
%
\begin{figure}[h!tbp]
  \centering
  \includegraphics[width=\textwidth]{time_diff}
  \caption{Boxplot of the median time required for the execution of 30 
  instances of function $f_4$, in seconds, different number of workers and populations sizes.  }
  % Which function? - JJ
  \label{fig:spworker}
\end{figure}
%
\begin{table}[]
  \caption{The median of the time required to finish an instance of the function $f_4$, 30 runs
  with different number of workers and populations} % time or rate? - JJ
  \label{tab:time}
  \vspace{0.25cm}
    \centering
    \begin{tabular}{ccrr}
    \hline
              &         & 5 Populations    & 10 Populations \\
     Dimension& Workers & Median of rate & Median of rate  \\
    \hline
          2   & 1w      & 2.96   & 3.15   \\
              & 2w      & 1.84   & 1.72   \\
              & 4w      & 1.22   & \textbf{0.96}   \\
              & 8w      & 1.05   & \textbf{0.59}   \\
    \hline
          3   & 1w      & 6.53   & \textbf{7.76}   \\
              & 2w      & 3.64   & 3.83   \\
              & 4w      & 2.33   & 2.26   \\
              & 8w      & 2.17   &  \textbf{1.36}   \\
    \hline
          5   & 1w      & \textbf{12.33}  & 14.19  \\
              & 2w      & 6.63   & \textbf{7.41}   \\
              & 4w      & 4.25   & 4.34   \\
              & 8w      & 3.67   &  \textbf{2.41}   \\
    \hline
          10  & 1w      & \textbf{31.50}  & 38.30  \\
              & 2w      & \textbf{16.07}  & 19.31  \\
              & 4w      &  9.99   & 10.35  \\
              & 8w      & 8.97   &  \textbf{5.92}  \\
    \hline
          20  & 1w      &  116.35 & 124.51 \\
              & 2w      & \textbf{51.18}  & 63.68  \\
              & 4w      & 32.26  & 33.07  \\
              & 8w      & 28.64  & \textbf{18.25}  \\
    \hline
          40  & 1w      & \textbf{369.89} & 448.89 \\
              & 2w      & \textbf{198.43} & 234.50 \\
              & 4w      & 122.39 &  120.62 \\
              & 8w      & 122.31 & \textbf{63.35} \\
    \hline
  \end{tabular}
\end{table}


%
%
\begin{figure}[h!tbp]
  \centering
  \includegraphics[width=\textwidth]{evalspersecond}
  \caption{Boxplot of the number of evaluations per second, for 30 instances of function $f_4$, with different number of workers and populations sizes }
   
  % Which function? - JJ
  \label{fig:spworker}
\end{figure}

\begin{table}[h!tbp]
  \caption{Speedup by worker and dimension, taking one worker as the baseline.}
  \label{tab:speedup-table}
  \vspace{0.25cm}
  \centering

  \begin{tabular}{c|r|r|r|r|r|r|}
  \cline{2-7}
  \multicolumn{1}{l|}{}           & \multicolumn{3}{c|}{5 Populations}                                          & \multicolumn{3}{c|}{10 Populations}                                         \\ \hline
  \multicolumn{1}{|l|}{Dimension} & \multicolumn{1}{c|}{2W} & \multicolumn{1}{c|}{4W} & \multicolumn{1}{c|}{8W} & \multicolumn{1}{c|}{2W} & \multicolumn{1}{c|}{4W} & \multicolumn{1}{c|}{8W} \\ \hline
  \multicolumn{1}{|c|}{2}         & 1.94                    & 3.12                    & 3.86                    & 1.84                    & 3.38                    & 5.98                    \\ \hline
  \multicolumn{1}{|c|}{3}         & 1.93                    & 2.77                    & 3.15                    & 1.90                    & 3.26                    & 5.96                    \\ \hline
  \multicolumn{1}{|c|}{5}         & 1.91                    & 2.90                    & 3.09                    & 1.91                    & 3.46                    & 6.14                    \\ \hline
  \multicolumn{1}{|c|}{10}        & 1.92                    & 3.03                    & 3.30                    & 1.90                    & 3.61                    & 6.41                    \\ \hline
  \multicolumn{1}{|c|}{20}        & 1.91                    & 3.14                    & 3.27                    & 1.89                    & 3.73                    & 6.71                    \\ \hline
  \multicolumn{1}{|c|}{40}        & 2.00                    & 2.92                    & 3.12                    & 1.95                    & 3.80                    & 7.52                    \\ \hline
  \end{tabular}
\end{table}
%

\begin{table}[h!tbp]
  \small
  \caption{Speedup achieved with incrementing the number of workers for each dimension showing the p-rate for the Wilcoxon test}
  % mark significant differences in some way - JJ
  \label{tab:speedup:test}
  \vspace{0.25cm}
  \centering
  \begin{tabular}{lllllll}
            &               &               & \multicolumn{2}{l}{5 Populations} & \multicolumn{2}{l}{10 Populations} \\
  Dimension & \multicolumn{2}{l}{Increment} & Speedup         & p-value         & Speedup          & p-value         \\
  2         & 1w            & 2w            & 1.94            & 6E-16           & 1.84             & 2E-16           \\
            & 2w            & 4w            & 1.61            & 2E-15           & 1.83             & 1E-15           \\
            & 4w            & 8w            & 1.24            & 1E-06           & 1.77             & 2E-16           \\
  3         & 1w            & 2w            & 1.93            & 2E-16           & 1.90             & 2E-16           \\
            & 2w            & 4w            & 1.44            & 8E-15           & 1.71             & 2E-16           \\
            & 4w            & 8w            & 1.14            & 3E-05           & 1.83             & 2E-16           \\
  5         & 1w            & 2w            & 1.91            & 9E-16           & 1.91             & 2E-16           \\
            & 2w            & 4w            & 1.52            & 3E-11           & 1.82             & 2E-16           \\
            & 4w            & 8w            & 1.06            & 5E-03           & 1.77             & 2E-16           \\
  10        & 1w            & 2w            & 1.92            & 3E-16           & 1.90             & 2E-16           \\
            & 2w            & 4w            & 1.58            & 3E-16           & 1.89             & 2E-16           \\
            & 4w            & 8w            & 1.09            & 1E-03           & 1.78             & 2E-16           \\
  20        & 1w            & 2w            & 1.91            & 2E-16           & 1.89             & 2E-16           \\
            & 2w            & 4w            & 1.64            & 2E-15           & 1.97             & 2E-16           \\
            & 4w            & 8w            & 1.04            & 1E-02           & 1.80             & 2E-16           \\
  40        & 1w            & 2w            & 2.00            & 2E-16           & 1.95             & 2E-16           \\
            & 2w            & 4w            & 1.46            & 1E-09           & 1.95             & 2E-16           \\
            & 4w            & 8w            & 1.07            & 3E-02           & 1.98             & 2E-16          
  \end{tabular}
  \end{table}

\subsection{Experimental Results} 
\label{results}

In this experiment, we wanted to test how the number of workers affected the
time needed to reach a solution and the speedup that each configuration can
produce. Adding more populations might add more overhead, so this might have a
noticeable effect. In principle, the main issue is how to find the right number
of workers for a particular problem, but in general, we wanted to check the
communication overhead when the size of the problem increases and how the
presented framework reacted to it.    % Added some explanation % here - JJ
We report the comparison regarding the execution time in Section~\ref{sec:exec-time}
and the summary of the speedup in section Section~ref{sec:speedup}.

\subsubsection{Execution Time}
\label{sec:exec-time}

Figure \ref{fig:spworker} shows the execution time achieved by a certain number of
workers, for every problem dimension, which, besides, changes the
population size.
Each box-plot indicates the time required for the execution of 30 function
instances, in seconds. Each row has a different scale on the y-axis, to
compensate for the dimension increments. It is important to notice that the
execution time can also be affected by the algorithm finding a solution with an
error smaller than the threshold, before completing all the FEs. 

In Table~\ref{tab:time} we can see that as expected, and in most cases, 
increasing the number of workers reduces the time
required for the execution of an instance, 
mainly when using the same parameters
(number of populations and number of workers), that is, performance
scales with the number of workers for a fixed problem and number of
sub-populations used. The exception is the case when using five populations;
the time does not decrease when progressing from four to eight workers.  
That is because most of the time, workers are waiting for a population 
to be available in the message queue.

However, when we compare the two
options, we find some subtle differences: When using one or two
workers, using 5 populations takes less time in most cases. 
In Table~\ref{tab:time} results with p-value of the two-tailed Wilcoxon
signed-ranks test was grater than the level of significance of 0.05 
(i.e., accepting the null hypothesis of inequality) are marked in boldface.
A reason for this could be that the migration of individuals takes more time to
reach the worker. For instance, when a single worker has 10 populations, only
after processing every one of them, it will start receiving mixed populations.  Although, in
all cases, and even a single worker, populations are heterogeneous, this
advantage takes more time to propagate. With four workers, almost the same
results can be achieved regardless of our selection between five or ten
populations. Also, there is not much difference between 4 and 8 workers, when
using five populations, which might indicate that some workers are
idling while populations are being processed by other workers. In
general, we can observe that keeping a ratio close to 1:1, but a bit
better than that, between the number of workers and populations, better exploits the computing
resources available. This also decreases the relation between the
overhead needed to migrate and process incoming and outgoing
population and the total computing time: more populations will need
more time to do that.


\subsubsection{Speedup}
\label{sec:speedup}

% TBD? - JJ

% No idea where this fits in. I think it's the second question in 7, so it should probably be a subsection - JJ
\section{Performance of Heterogeneous Populations in the BBOB Benchmark}
\label{sec:exp2}

\begin{figure*}[h!tb]
  \begin{tabular}
      {c@{\hspace*{-0.00001\textwidth}}
       c@{\hspace*{-0.00001\textwidth}}
       c@{\hspace*{-0.00001\textwidth}}
      }
  GA  &  PSO & GA \& PSO\\   
  \includegraphics[width=0.30\textwidth]{GAOnly_f001}&
  \includegraphics[width=0.30\textwidth]{PSOOnly_f001}&
  \includegraphics[width=0.30\textwidth]{GAPSO_f001}\\

  \includegraphics[width=0.30\textwidth]{GAOnly_f002}&
  \includegraphics[width=0.30\textwidth]{PSOOnly_f002}&
  \includegraphics[width=0.30\textwidth]{GAPSO_f002}\\

  \includegraphics[width=0.30\textwidth]{GAOnly_f003}&
  \includegraphics[width=0.30\textwidth]{PSOOnly_f003}&
  \includegraphics[width=0.30\textwidth]{GAPSO_f003}\\

  \includegraphics[width=0.30\textwidth]{GAOnly_f004}&
  \includegraphics[width=0.30\textwidth]{PSOOnly_f004}&
  \includegraphics[width=0.30\textwidth]{GAPSO_f004}\\

  \includegraphics[width=0.30\textwidth]{GAOnly_f005}&
  \includegraphics[width=0.30\textwidth]{PSOOnly_f005}&
  \includegraphics[width=0.30\textwidth]{GAPSO_f005}\\
  \end{tabular}
  \vspace{-3ex}
   \caption{
Scaling of expected runtime (RT defined as the number of function
evaluations to reach a target function value for the first time) for  
each problem dimension. Target values $\Delta f$ = 10, 1, $10^{-1}$, $10^{-2}$,$10^{-3}$,$10^{-5}$,$10^{-8}$
(the exponent and line colors are given in the legend of $f_1$ in the top row). 
Lines are the average RT (aRT); Cross ($+$): median RT of successful runs to reach
the most difficult target that was reached at least once (but not always);
Cross (\textcolor{red}{$\times$}): maximum number of f-evaluations in any trial. 
All values are divided by dimension and plotted as $log_{10}$ values versus dimension.
% More explanation for those not familiar with BBOB - JJ
% I think is more clear? - M
}
\label{fig:bbob}
\end{figure*}


\subsection{Setup}

A multi-population based algorithm can decrease the execution time
because of parallel execution. But, having heterogeneous 
populations might enhance evolutionary search and avoid unneeded
evaluations more than homogeneous systems systems do; heterogeneous settings, if
done right, increases the diversity of the whole population\cite{araujo2008multikulti}.

But this is a rule of thumb, and it will depend on the degree of heterogeneity,
as well as on the algorithm itself. Some level of heterogeneity can be
implemented by just changing the configuration parameters of each population,
as in the previous experiment, but in this case, we are interested in a heterogeneous search strategy.

Therefore, in this experiment we compare a multi-population with  GA- and PSO- only populations,
versus an ensemble of GA and PSO algorithms. We have tested on the first five functions of the
BBOB testbed; we have used ten populations and eight workers for the experiment and the
same parameters as before.

\subsection{Experimental Results} 

The results obtained by the experiments show (see Figure \ref{fig:bbob}) how
the runtime scales with dimension to reach certain target values $\Delta f$;
The color of the lines indicates the average runtime, for each target reached
at least once. A red circle without a number on top indicates the algorithm
has reached the $10^{-8}$ target on all instances for that dimension. If there
is that number, it indicates how many times the algorithm has reached
the target. Fixed values of targets $\Delta f = 10^{k}$ with $k$ colors are
given in the legend of $f_1$ in the top row, $k$ values are $[-8,-5,-3,-2,-1,0,1]$. Results
from each configuration are presented in each column, GA, PSO, and GA\&PSO
populations. % clarify which colors for every level - JJ
% colors are shown in the figure, I put a hint that is in the top row. 
% But I can list them if that is better - M

We can see that the GA algorithm (on the leftmost column) has a hard time reaching even the
$10^{-5}$ target in functions ($f_1-f_4$) for all dimensions, and has the worst
performance in 20 and 40 dimensions. Finally, it performs better on $f_5$
reaching the $10^{-8}$ on all dimensions but with a higher runtime on lower
dimensions.

On the other hand, the multi-population PSO (taking the column on the middle) 
has better performance; its results are spread over a smaller range,
reaching all targets for functions $f_1$ and $f_2$ but with a slightly higher
runtime than the multi-strategy configuration. It is not able to reach the
$10^{-8}$ target on the higher dimensions of $f_3$ and $f_4$. Moreover, the PSO
multi-population has the best runtime for the lower dimensions of $f_5$.

Finally, the proposed PSO\&GA mixed algorithm has reached the $10^{-8}$ target
value on all functions ($f_1-f_5$) and scales well to higher dimensions, even on
$f_3$ and $f_4$ (charts on the lower rows), which are usually considered
difficult functions. This experiment also exemplifies the type of analyses that
we can perform with the results of the EvoSwarm application by reusing the COCO framework.
We also proved that multi-population algorithms can be compared under the same 
conditions, including single and multi-algorithm versions, and results show 
that the later have better performance.

% If this is what you want to prove, it's not a very strong point. Maybe it
% would be stronger if you proved that these mixed algorithms can be tested in the
% same conditions as single-algorithm, and also that these mixed algorithms work
% better than single-algorithm versions - JJ
% Ok, stated like that - M

\section{Deploying to a cloud provider}
\label{cloud-aws}
Container-based applications describe the deployment of loosely coupled
processes in a consistent and portable way, in every phase of the life cycle of
an application, from development through testing to production independently on
the kind of infrastructure. The term cloud-native describes these
container-based environments because they are deployed on an infrastructure that
abstracts the underlying compute, storage, and networking primitives. This
infrastructure does need to be a cloud provider; it could be a developer's
laptop, a single server, or a production environment. When we deploy a
cloud-native application to a cloud provider, we have some more options to
choose:

\begin{description}
  
  \item[A virtual machine] with a container-optimized operating system, for example,
  Google Compute Engine VMs, or Amazon EC2.  We still need to provision the
  virtual machine and run docker-compose commands as we would do in a local 
  workstation. Salza et al. \cite{salza2019speed} tested this option by using
  CoreOs cluster. 

  \item[A Kubernetes cluster] provides auto-scaling and management of containerized
  applications, but it needs additional configuration for provisioning. All major
  cloud-providers have Kubernetes services.

  \item[A container orchestration service] these services are compatible with docker-compose
    files for configuration and provide transparent provisioning. Examples of these
    services are Amazon Elastic Container Service,  Red Hat Openshift, and Marantis Docker Enterprise.

\end{description}
    
As a proof-of-concept, we chose the third option, that is, a container orchestration service, and deployed the EvoSwarm application in Amazon Elastic
Container Service (ECS),  since it needs fewer changes in configuration 
(from deploying it locally using docker-compose) and it is has a lower cost than the Kubernetes alternative. % Remember to mention cost at the end - JJ

We can define an ECS cluster directly on AWS Elastic Cloud VMs or through the AWS Fargate service.
Fargate is a serverless compute engine for containers that provides automatic provision 
and management of AWS ECS resources. With this service, calculating the cost of execution
is simplified because users only specify the computing units and memory for all the application,
instead of every component. 

Multicontainer applications are deployed to ECS as tasks, and a single cluster can run multiple tasks in
parallel. When using the Fargate service as a backend, tasks are limited to a
maximum of 10 containers.  

Using the ECS CLI, we can provision a cluster with a configuration file
specifying the computing resources needed. We can specify the configuration of a task 
by using a task definition file (see Listing~\ref{code:ecs}) in YAML format.
The main attributes are the {\texttt task\_size} indicating the memory and CPU units
assigned, and network configuration. The complete configuration is generated
by the {\texttt ecs compose command} that uses a {\texttt docker-compose.yml} file to generate 
the configuration on-the-fly. For example to deploy the controller, setup and redis 
containers we used the file in Listing ~\ref{code:compose}.
Each container is defined as a  {\texttt service} , with the following attributes: {\texttt image},
that reference the container images we have published in Docker hub
\url{https://hub.docker.com/u/mariosky}, open {\texttt ports}, a {\texttt command} to be executed at
startup, configuration for the AWS {\texttt logging} service, and finally {\texttt environment}
variables used by code running inside containers.


We deployed two configurations, one that included all containers in a single task,
and another one, where we assigned each worker to a different task and the controller, 
redis, and setup in another, for a total of nine concurrent Fargate tasks. 

For the first option, we deployed an AWS Fargate cluster and defined a task configuration file with
8GBs of memory and 4096 computing units, equivalent to 4 CPUs. Because of the
ten container limit, we only used seven workers and tested function $f_4$ as
in the previous experiment, and to save resources we only tested for dimensions 10 and 20 for 15 instances.

For the second option, we used the same cluster and additionally
assigned each worker to a task with 4GBs of memory and 2048 computing units. Then scale the 
number of worker tasks to eight. We can scale the number of tasks for up to 100 instances in 
a Fargate configuration. 

\begin{lstlisting}[caption=ecs-params.yml , label=code:ecs]
version: 1
task_definition:
  task_execution_role: ecsTaskExecutionRole
  ecs_network_mode: awsvpc
  task_size:
    mem_limit: 8GB
    cpu_limit: 4096
\end{lstlisting}
% Do you need the details about the subnets? As long as they are here,
% you'll have to explain them. Why two subnets? It's probably better to
% leave that network configuration out anyway - JJ
% Ok, I removed that section. those parameters are required, but are used 
% internally by the cluster. - M 
% The security group was required to have external access to redis. - M
% Please clarify that those images are published in Docker hub by yourself - JJ
% I have done this a few commits back. (4 paragraphs up) - M

\begin{lstlisting}[caption={docker-compose.yml for setup, controller and redis containers}, label=code:compose]
  version: '3'
  services:
    redis:
      image: "redis:alpine"
      ports:
        - "6379:6379"
      logging:
        driver: awslogs
        options:
          awslogs-region: us-west-2
          awslogs-group: docker-logs
          awslogs-stream-prefix: redis
  
    setup:
      image: mariosky/setup
      command: python experiment.py
      environment:
        PYTHONUNBUFFERED: 1
        REDIS_HOST: localhost
      logging:
        driver: awslogs
        options:
          awslogs-region: us-west-2
          awslogs-group: docker-logs
          awslogs-stream-prefix: setup
        
    controller:
      image: mariosky/controller
      command: python controller.py
      environment:
          PYTHONUNBUFFERED: 1
          REDIS_HOST: localhost
      logging:
        driver: awslogs
        options:
          awslogs-region: us-west-2
          awslogs-group: docker-logs
          awslogs-stream-prefix: controller
  \end{lstlisting}
% You will probably need to explain this a bit - JJ 
% done - M  
\subsection{Experimental Results} 


The results are shown in Figure~\ref{fig:aws-results} and Table~\ref{tab:aws}. 

As we can see, the local environment (see section \ref{setup}) achieved a higher
ratio of evaluations per second (in bold). Still, we must consider that there is a minimum
network overhead in a local workstation and a clock speed of 3.8 GHz. The first
option (labeled Single) is straightforward to deploy, needing only a single
docker-compose file, and one command to execute. But with the limit of 4CPUs and
ten containers, it is the slower option. The second option (labeled Multi), is
faster, and not too far from the local execution, especially when solving the
$f_4$ in 20 dimensions (underline in table). With the capacity for increasing the number of worker
containers, it is reasonable to think that we can achieve a higher number of
evaluations with an appropriate configuration. Nevertheless, the goal of this
experiment was not to increase the number of evaluations but to test the
flexibility of a cloud-native application.

\begin{figure}[h!tbp]
  \centering
  \includegraphics[width=\textwidth]{aws}
  \caption{Boxplot of the number of evaluations per second, for 15 instances of function $f_4$,
   with three execution environments Local, Single task and Multi-task.
   }
  \label{fig:aws-results}
\end{figure}
%
\begin{table}[h!tbp]
  \small
  \caption{ Median number of the evaluations per second ratio, for 15 instances of function $f_4$,
  with three execution environments Local, Single task and Multi task}
  \label{tab:aws}
  \vspace{0.25cm}
  \centering

  \begin{tabular}{lll}
  \hline
  Dim & Env         & Median of ratio \\
  \hline
  10  & Local       & \textbf{47,166.29}       \\
      & Multi task  & 40,466.45    \\
      & Single task & 18,193.05      \\
  \hline
  20  & Local       & \textbf{36,101.86}   \\
      & Multi task  & {\ul 33,916.02}       \\
      & Single task & 16,546.95  \\
  \hline
  \end{tabular}
\end{table}




\section{Conclusions} 
\label{conclusions}

In this paper we have presented the EvoSwarm framework that implements
an event-based, cloud native architecture suitable for hosting any
kind of multi-population optimization algorithm. The framework is
based in industry-standard development tools such as Docker and Docker
Compose, making easy to develop and deploy multi-algorithm distributed
experiments.

The set up of this kind of algorithms will have a big influence on the
results, since diversity is important for this kind of algorithms and
its creation and destruction play a big part of the algorithm's
performance. One of the main levers to control it in EvoSwarm is via
the number of workers that will be allocated from the beginning, which
is why we have performed an experiment mainly intended as a proof of
concept, but also devoted to show how two parameters in the framework,
number of workers and number of populations used to initially seed the
system, interact with each other. The conclusion of this experiment is
that there is an interesting interplay, with the most benefit being
obtained with a number of populations equal to the number of workers
or slightly inferior or superior, which brings algorithmic benefit
(experiment taking less time because it needs less evaluations) and
also performance benefits (experiment taking less time because
evaluations are being split between different workers.

% this is not a conclusion. The conclusion is an answer to the
% research question. This works, and works precisely for the reasons
% we say it works. - JJ
% Again, revise search questions and explain answers - JJ
As a conclusion, EvoSwarm is a framework designed and tested according
to industry standards which is able to bring many benefits to the
bioinspired algorithm community, by showing the possibility of
creating new, high performance, mixed algorithms, which can also be
easily deployed to the cloud, or locally to systems that simply need
to have Docker and Docker Compose installed.

It also opens new possibilities. From the design point of view, it
would be interesting to try and use automatic scaling, instead of
setting the number of workers by hand. This would need a certain
amount of redesign, the most important of which would be using
container orchestration systems such as Kubernetes or Docker
Swarm. Instead of setting a fixed number of workers, only the maximum
amount would need to be established, which could be done directly or
by setting an evaluation budget.

From the algorithmic point of view, there are many possible lines of
research. Mixing population-based algorithms with other algorithms
would be a possibility, but also using different instances of
population based algorithms, such as checking how Estimation of
Distribution Algorithms would work together with evolutionary
algorithms. EvoloPy also includes other population based algorithms,
which could be tested, trying to find out which sets of algorithms are
a better match to each other. All these will be explored as future
lines of work.

\section{Acknowledgements}

This paper has been supported in part by projects TecNM-5654.19-P and DeepBio
(TIN2017-85727-C4-2-P).

\section*{References}

\bibliographystyle{elsarticle-num}
\bibliography{multipopulation}

\end{document}